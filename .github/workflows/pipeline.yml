name: UFC Lakehouse (extract -> upload -> run)

on:
  workflow_dispatch:
  schedule:
    # 07:00 no Brasil (America/Sao_Paulo) ~ 10:00 UTC
    - cron: "0 10 * * *"

jobs:
  pipeline:
    runs-on: ubuntu-latest

    env:
      MAX_EVENTS: 10
      MAX_FIGHTERS: 50
      FIGHTER_LOG_EVERY: 10
      RATE_LIMIT_SLEEP: 0.5
      RATE_LIMIT_SLEEP_FIGHT: 0.0

      DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
      DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
      DATABRICKS_USER: ${{ secrets.DATABRICKS_USER }}
      DATABRICKS_JOB_ID: ${{ secrets.DATABRICKS_JOB_ID }}

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Debug paths
        run: |
          pwd
          ls -la
          echo "GITHUB_WORKSPACE=$GITHUB_WORKSPACE"

      - name: Extract landing ZIP
        env:
          MAX_EVENTS: ${{ secrets.MAX_EVENTS }}
        run: |
          export RUN_DATE=$(date -u +%F)
          python -m tools.extract_landing
          ls -lah out/dt=${RUN_DATE}

      - name: Upload ZIP to Workspace Files (WSFS)
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
          DATABRICKS_USER: ${{ secrets.DATABRICKS_USER }}
        run: |
          RUN_DATE=$(date -u +%F)

          # acha o zip dentro da pasta do run
          LOCAL_ZIP=$(find "out/dt=${RUN_DATE}" -maxdepth 3 -type f -name "*.zip" | head -n 1)
          echo "LOCAL_ZIP=${LOCAL_ZIP}"
          test -f "${LOCAL_ZIP}"

          # Paths corretos para Files API: /Users/<user>/...
          WS_DIR="/Users/${DATABRICKS_USER}/ufc-lakehouse/landing/dt=${RUN_DATE}"
          WS_FILE="${WS_DIR}/ufc_landing.zip"

          # cria diret√≥rio
          curl -sS -X PUT "https://${DATABRICKS_HOST}/api/2.0/fs/directories${WS_DIR}" \
            -H "Authorization: Bearer ${DATABRICKS_TOKEN}"

          # upload do zip
          curl -sS -X PUT "https://${DATABRICKS_HOST}/api/2.0/fs/files${WS_FILE}?overwrite=true" \
            -H "Authorization: Bearer ${DATABRICKS_TOKEN}" \
            -H "Content-Type: application/octet-stream" \
            --data-binary "@${LOCAL_ZIP}"

          echo "WS_FILE=${WS_FILE}"

      - name: Trigger Databricks job
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
          DATABRICKS_JOB_ID: ${{ secrets.DATABRICKS_JOB_ID }}
          DATABRICKS_USER: ${{ secrets.DATABRICKS_USER }}
        run: |
          RUN_DATE=$(date -u +%F)
          LANDING_ZIP="/Users/${DATABRICKS_USER}/ufc-lakehouse/landing/dt=${RUN_DATE}/ufc_landing.zip"

          curl -sS --location --request POST "https://${DATABRICKS_HOST}/api/2.2/jobs/run-now" \
            --header "Authorization: Bearer ${DATABRICKS_TOKEN}" \
            --header "Content-Type: application/json" \
            --data "{
              \"job_id\": ${DATABRICKS_JOB_ID},
              \"notebook_params\": {
                \"landing_zip\": \"${LANDING_ZIP}\",
                \"run_date\": \"${RUN_DATE}\"
              }
            }"
